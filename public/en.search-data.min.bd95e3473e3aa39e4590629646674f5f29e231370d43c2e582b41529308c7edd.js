'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/posts/','title':"Posts",'content':""});index.add({'id':1,'href':'/posts/whispersync-reverse-engineering/','title':"Reverse engineer whispersync",'content':"I am big fan of my Kindle. This would be the device I\u0026rsquo;d brung over to a desert island. I am also a fairly frequent user of the highlight feature. One thing is bothering me though : the lack of open API on the Kindle to retrieve the data about me. Amazon provides the my-clippings.txt file on the Kindle and the \u0026ldquo;Export my annotations via e-mail\u0026rdquo; feature, but both theses feature cannot run in the background, and do not retrieve the last read position. I want moar !\nI want to get the raw data for example:\n to print a little book with all my annotations to print all annotations and make a wallpaper for my toilets ü§î retrieve my last read position and see in which periods of my life I tend to read most (reading less would be a good indicator of stressful periods) put the data in my own personal space : my cozy. I could for example display a random highlight in my Home, or have a \u0026ldquo;books\u0026rdquo; app with a public page with all my books. That would as a digital equivalent of a library, something that is lost with the Kindle, something that I find a bit sad since it is really interesting to see other people\u0026rsquo; books.  The possibilities are endless\u0026hellip; but first, I needed to get access to my data. A long time ago, I tried to access this data via Kindle web but could not pass the login screen via scraping : there was if I recall well, encryption going on the front-side.\nRecently, a colleague made a presentation at work on using mitmproxy to discover HTTP APIs used by apps. It gave me motivation to start again on this project: This time, instead of web scraping, I\u0026rsquo;d try to understand how the Kindle communicates with Amazon and try to emulate the same HTTP requests.\nSetup To see the flow of communication between an Android device and a remote HTTP based APIs, things are a bit more involved that the same thing from a web browser : in the web world we have access to the network inspector that help us record data, replay calls, see responses in requests in pretty tabs etc\u0026hellip; There is no such thing for Android or iOS. The solution is to do a man-in-the-middle attack on our device : proxying and recordding all traffic through a controlled access point.\nThe setup is briefly described below:\n Raspberry Pi running as a wifi access point (hostapd) Every packet going through the access point is redirected to mitmproxy (transparent mode) HTTPs deciphering possible since a custom SSL certificat is installed on the target device (on Android, possible to use for apps until Android 6) Genymotion with Android 5 Kindle for Android installed on Genymotion  A good article to set everything up is https://www.dinofizzotti.com/blog/2019-01-09-running-a-man-in-the-middle-proxy-on-a-raspberry-pi-3/.\nAfter all this setup (a bit long and tedious but not hard), it is possible to record HTTP dumps of the traffic between the Kindle app and Amazon.\nssh pi@192.168.50.10 tmux a -t 0 # launch mitmdump and write request/response to outfile mitmdump --mode transparent -w outfile # Use the Kindle app to generate traffic # ctrl-c to stop the proxy exit # outfile contains all the requests and responses in the mitmproxy format.\nRecording HTTP dumps mitmproxy uses a custom format to store dumps. It is not very interoperable. HAR is a standard format used for example in Chrome and Firefox (Network inspector tabs in both browser can import/export the HAR format). The HAR format underlying format is JSON which makes it readable and interoperable with tools like jq that are really handy for filtering / querying.\nThe mitmproxy repository contains a script to transform a mitmproxy dumpfile into a HAR file.\nTo convert a mitmproxy dump into HAR:\n# Clone the mitmproxy repository git clone https://github.com/mitmproxy/mitmproxy.git # Install mitmproxy pip install mitmproxy # Extract the dump from the Raspberry Pi rsync -aPrs pi@192.168.50.10:outfile dump.mitmproxy export HAR_DUMP_PY_PATH=$MITMPROXY_REPOSITORY_PATH/examples/complex/har_dump.py # Convert mitmproxy format to HAR format (JSON based format) mitmdump -vvv -n -r infile.dump -s $HAR_DUMP_PY_PATH --set hardump=./outfile.har Understanding the flow With jq, we can see extract requests URLs, which is handy to start understanding the flow of communication between Amazon and our device.\n$ cat dumps/dump.har | jq -rc \u0026#39;.log.entries | map(.request.url)\u0026#39; \u0026#34;https://54.239.22.185/FirsProxy/registerDevice\u0026#34;, \u0026#34;https://54.239.22.185/FirsProxy/registerDevice\u0026#34;, \u0026#34;https://54.239.22.185/FirsProxy/registerDevice\u0026#34;, \u0026#34;https://54.239.22.185/FirsProxy/registerDevice\u0026#34;, \u0026#34;https://54.239.22.185/FirsProxy/getStoreCredentials\u0026#34;, \u0026#34;https://52.46.133.19/FionaTodoListProxy/syncMetaData\u0026#34;, # Unique URLS cat dumps/dump5.har | jq \u0026#39;.log.entries | map(.request.url) | sort | unique\u0026#39; # Select all requests with a particular URL cat dumps/dump5.har | jq \u0026#39;.log.entries | map(select(.request.url == \u0026#34;\u0026lt;MY_URL\u0026gt;\u0026#34;))\u0026#39; Registration and request signing The first call the device makes when logging in is a registerDevice call. It contains both login and password and is used to register a device on Amazon. After replaying the request, I had a \u0026ldquo;Wrong password\u0026rdquo; response. It is because Amazon\u0026rsquo;s sends a 2FA email and you have to replay (again) the registerDevice call with the value from the 2FA email in the password field to get through.\nAt this point a new device is visible on Amazon Kindle site üôå\nThe problem now is that we can see that every subsequent request to Amazon has a X-ADP-Request-Digest : every request is \u0026ldquo;signed\u0026rdquo; with the help of a certificate received in the registerDevice call üò±.\n{ \u0026#34;startedDateTime\u0026#34;: \u0026#34;2020-05-10T14:21:42.217752+00:00\u0026#34;, \u0026#34;time\u0026#34;: 6532, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://52.46.133.19/FionaTodoListProxy/syncMetaData\u0026#34;, \u0026#34;httpVersion\u0026#34;: \u0026#34;HTTP/1.1\u0026#34;, \u0026#34;headers\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;X-ADP-Request-Digest\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;SIG1tis85OWFqJqbzy0Z0xBzBCI3/88e9p/2jr8UvTAUQCuil5ED0833peNeKPp1dIMdVAs/INcUR//xvCJu+ngyP9olVSda/IBBxM2fftVGIDEVuQqMSC9P+O/pZMhaAJpvxIm78M52OB+lNIYXjE0Kr1OB0mmOo4iVu45aRio8hZDlmDG07zjVHnlQHE5sUjzOMnYBFC6VXw+srjYfo6dTptwSKNX11A0naG+tjcuxnglAE3R9U8/+pVr/uFNT4ou+0cQs2KbV0/4tYEIbOogC1JgjNNt4hyb2l91QED7Aj+A/DFcKBT+XNkjAUAAI1//HhCtxqCNtbu1E1sRReQ==:2020-04-10T14:21:40Z\u0026#34; Fortunately, after a bit of searching I came across the repositories of lolsborn (readsync and fiona-client) that had implementation of request signing for the whispersync API.\nWith the help of node-forge and node-rsa, after a fair bit of struggle, I managed to have the right signature. I found it difficult even with two example implementations to get the signature exactly right ( I am not an expert in crypto technologies and did not know both libraries, so I spend a little bit of time trying to jam the certificate and values in every possible ways üôÉ). I had to use two different libraries to get the same signature. I am sure it is possible to use only node-forge though.\nUsing a recorded dump to have an example of the right signature and using it in a Jest test was very helpful as the feedback loop was very quick.\n ‚ÑπÔ∏è The private key is a PKCS8 certificate in DER format encoded in base64.\n  ‚ùìI wonder why to sign the requests, the devices do not generate a private/public key pair and transmit the public key to Amazon : it is a bit unusual to have something private fly on the network.\n Sidecars After cracking the signing part, it was possible to call the syncMedata route, with a proper digest header, to get all the books in our library (yay !).\nBut, the challenge was not done yet: I was most interested in getting the metadata on the book: my highlights, annotations and last page read.\nWhen searching for the content of a highlight in the dump, I could not find anything ü§î. When filtering the URLs of the dump with the identifier of the book (the ASIN in Amazon parlance), some URLs looked interesting:\nhttps://72.21.194.248/FionaCDEServiceEngine/FSDownloadContent?type=EBOK\u0026amp;key=\u0026lt;MYASIN\u0026gt; https://54.239.26.233/FionaCDEServiceEngine/sidecar?type=EBOK\u0026amp;key=\u0026lt;MYASIN\u0026gt; FSDownloadContent was the call to get the content of the book. But what was the sidecar URL ? Sidecars sounds like something loaded to the side of the book, maybe containing annotations ?\nThe body of the response was base64 encoded, and after a base64 --decode, bingo ! I could read the content of my book highlights into my terminal.\n Now, this is a proper sidecar\n  $ yarn -s cli fetch sidecar --no-parse B01056E716 | base64 --decode CR!3WET39TJ553PXCAHWBHXQ1RT_PAR^Ãµ]^Ãµ]BPARMOBI\u0026amp;\u0026amp;\u0026lt;@6^^ !b#f$%*f\u0026#34;V F BPAR8FYDATApce plaisir puis dans l agressivit ainsi que cet amour de la servilit grgaire n DATAC tait la mme illusion, procdant de la mme volont de s illusionner soi-mme.8 DATAon n avait pas encore invent le systme actuel qui consiste assommer les gens coups de matraque et les exterminerDATAaffreuse tension. Le dimanche matin, la radio annonait la nouvelle que l Angleterre avait dclar la guerre l Allemagne. ƒà DATAils n aspiraient rien d autre qu enchaner, dans un effort silencieux et pourtant passionn, des strophes parfaites dont chaque vers tait pntr de musique, brillant de couleurs, clatant d images.P DATAnous qui attendons de chaque jour qui se lve des infamies pires encore que celles de la veille, nous sommes nettement plus sceptiques quant la possibilit d une ducation morale des hommes. BKMK4W*WW*ﬁ≠$#BKMK4^,^^,ﬁ≠BKMK4~y:~yﬁ≠BKMK4ﬁ≠! BKMK4`ﬁ≠BKMK1ﬁ≠BKMK4 (I\u0026rsquo;ve added line breaks for clarity)\nAs you can see, the problem was that the decoded content was a bit garbled : accents are missing and annotations are not delimited correctly. Turns out, Amazon uses a custom binary format for its sidecars. After encryption, binary decoding, what an adventure ü§† !\nWhen searching for the sidecar application type, I stumbled upon KSP (Kindle Server Proxy), a project to connect a Calibre library to the Kindle seamlessly. It works as a middleware between Amazon and your Kindle, implementing routes of the Whispersync API. It serves content from your Calibre database, or from Amazon as needed: if a book is from Amazon, content is served from Amazon, otherwise its served from a local database.\nUnfortunately, KSP did not need to read sidebars as it was sufficient for it to only pass the content without reading it. It did however need to know how to write sidebars. The code was informative on the binary format used, but I knew I needed to code a sidebar parser.\nBytes in color At this point, I decided to have a look at the bytes in a graphic form to understand better what was going on. I had read recently about mapping an ELF file onto a space-filling curve and coloring its bytes so I figured I could try to do the same thing. By reimplementing, I would have more control onto the visualisation and hopefully it would serve when debugging the parser.\nI fired up codesandbox and wrote an app that when given a base64 string would output its bytes colored based on the value of their value. I used the HSL color space with the value of the byte controlling the hue so that nearby valued bytes have similar colors. You can see the app here (TODO). It is very similar to cortesi\u0026rsquo;s binvis but this one I could hack more easily to serve my needs.\n Hmmm\u0026hellip; yummy ?\n  Seeing the data colored, you can quickly see the different parts of the binary format. For example the annotations are visible with their red-green checker pattern. This is indicative that every character is coded on 2 bytes : the annotations are encoded in UTF-16.\nThis app was really helpful when writing the parser since I could better understand at which point the parser was struggling etc\u0026hellip;\nTo write the parser, I used binary-parser. Its API make it easy to make a parser. To be able to conjugate it with the binary viewer, I monkey patched the code to add before/after indexes to each field so that I could see each field separately in the viewer.\nHere is an extract from the parser:\nconst sidecarParser = new Parser() .endianess(\u0026#39;big\u0026#39;) .string(\u0026#39;guid\u0026#39;, { length: 32, stripNull: true }) .seek(4) .buffer(\u0026#39;v1\u0026#39;, { length: 4 }) .buffer(\u0026#39;v2\u0026#39;, { length: 4 }) .buffer(\u0026#39;v3\u0026#39;, { length: 4 }) ... .uint16(\u0026#39;next_id\u0026#39;) .seek(4) .uint16(\u0026#39;index_count\u0026#39;) .seek(2) .uint16(\u0026#39;bpar_ptr\u0026#39;) .saveOffset(\u0026#39;bpar_ptr_index_\u0026#39;) Incredible endia\u0026hellip; To format the bytes, I used the Uint8/16 APIs from the browser that serves as views of the underlying buffer. This worked well for Uint8/16 int buffers. Only problem is that those APIs work in the platform endianness (to use the native APIs where possible). My computer was in little endian whereas the annotations were encoded in big endian utf16. This meant that if I wanted to read a buffer with String.fromCharCode I had either to swap the endianess of the buffer or to use a DataView (Javascript API to read / write data independent of the endianess of the platform).\nData corruption To test the parser, I downloaded sidecars through the whispersync client I was building and dumped their contents in the test folder. When trying to parse them, the parser was strugglig and I could see many \u0026ldquo;EF BF BD\u0026rdquo; bytes colored in blue.\nThose bytes were mainly present in the section of the binary containing pointers to the annotations locations. This made the parser fail. After a bit of struggling trying to shift the data or ignore those bytes, I searched for \u0026ldquo;EF BD BD\u0026rdquo; on DuckDuckGo.\n EF BF BD is UTF-8 for FFFD, which is the the Unicode replacement character (used for data corruption, when characters cannot be converted to a certain code page).\n https://stackoverflow.com/questions/47484039/java-charset-decode-issue-in-converting-string-to-hex-code\nI figured out that the request JS library used to fetch HTTP responses tried to decode the data as UTF-8 by default and failed (as sidecars are transmitted as binary data over the network). Solution was to put { encoding: null } as the request options so that it returns a Buffer. The buffer can then be encoded in base64 to print it to the console with no garbled character. This base64 output can piped into base64 --decode before dumping it to disk (console.logging the buffer would try to decode the data as utf-8).\nHTTP server to explore content At some point, to be able to explore annotations, it seemed to me that it was preferable to add an HTTP server serving an index of the books and a book page showing the annotations. The content is fetched from Amazon if it is not on disk, and it is then saved in JSON format for later access.\nI used fastify which is an alternative to express that promise to be much faster. It worked well for my simple purposes.\nConclusion The code is available here:\nAll in all, it was a really good experience, I learned about\n Man-in-the-middle in practice Encryption Binary decoding  There was a lot of hurdles but I was really pumped up by the fact that the data recovered was important to me : I like reading and am now happy that my highlights will live in a format that I will be able to read in a long time for now.\nNext plans: make a Cozy connector using the whispersync-client to have my annotations automatically synced to my Cozy üöÄ.\nResources Several resources were of great help when building this project.\n Lolsborn\u0026rsquo;s repos : readsync and fiona-client  Useful for request signing and starting out the Javascript structure of the Javascript client (turns out Scala is quite quick to convert to Javascript).\n KSP (Kindle Server Proxy)  Implementation of a middleware server for Kindle, seamlessly connecting Calibre and Kindle Recreates the sidecar, useful to understand how the format of the sidecar\n Reverse engineering a file format on WikiBooks.  Good general information on how to start with the decoding of a binary format.\n "});})();