'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/posts/zns-quest/','title':"Crowd creating a board game",'content':"My girlfriend graduated from her thesis last year üöÄüòç. With the help of many of her colleagues, we made her as PhD gift a custom board game, referencing at the good and challenging times of the thesis. There are some interesting bits here and there on its creation process that I wanted to share.\nCreating cards\u0026hellip;together The idea of this board game was simple. It is a turn by turn dice game where each player advances on a 65-squares path symbolizing the tortuous journey of a thesis. It is very similar to the squares and ladders game (or Goose game, \u0026ldquo;Jeu de l\u0026rsquo;oie\u0026rdquo; in French).\n ‚ÑπÔ∏è The name of the game is ZnS quest since the subject of the thesis was on the stability of nano-size zinc sulfide particles in organic matter.\n  After advancing, each players draws a card randomly from a deck. Each card has a picture, a description and a type. The type can be\n bonus/malus: making the player go forward/backward by some squares on the board challenge: you have to do something, eg: tell a joke, and then you can go forward friend: protects you against future maluses.  When starting with this idea, I was confident that to be successful, this game should have a lot of different cards otherwise it would soon be boring. Moreover, I wanted that each colleague could participate easily in the creation process. If anyone could create a card, we would have more cards. How to make this card creation process fast and easy for anyone ? I thought of using a Dropbox shared folder as a collaborative platform to generate cards.\nI tried to simplify the creation process as much as possible : A folder was shared with all the colleagues. This folder had 1 file describing all the cards and a folder containing all the pictures.\n People would edit the file thanks to the \u0026ldquo;Microsoft Word for web\u0026rdquo; The file was automatically synced to my computer I could run a script every couple of hours to generate the cards as PNG images. Each card was rendered inside the same synced shared folder so that everyone could see the cards they had created  Here is an excerpt from the file describing cards. Each line is in \u0026lt;number\u0026gt;. \u0026lt;type\u0026gt; | \u0026lt;title\u0026gt; | \u0026lt;description\u0026gt; format.\n18. Bonus | G√¢teau de PY | PY t\u0026#39;as fait un g√¢teau trop bon. üé≤ Si tu fais un 6, tu n\u0026#39;arrives plus √† bouger apr√®s la premi√®re part. Sinon avance d\u0026#39;1 case ! 300. Malus | Minion time | Tu te transformes en Minion pendant 1 week-end, recule d\u0026#39;1 page ! 301. Bonus | On est finale | L\u0026#39;OM est en finale de la coupe d\u0026#39;Europe, c\u0026#39;est le oa√Ø dans la rue ! Avance d\u0026#39;1 page Each photo in the picture folder is linked to the right line through the \u0026lt;number\u0026gt; part.\n List of pictures\n  The feedback loop was relatively short and people quickly bought in and added cards. At the end, more than 250 cards were created collaboratively üöÄ.\nGenerating the cards Here are some technical details on how the cards were generated.\nText ‚Üí SVG To create the cards from the data, I used SVG templating.\nWith the help of Handlebars (a Javascript templating engin), each card was rendered as SVG data. I first created the card layout in Sketch for WYSIWYG convenience. Then I exported the Artboard as an SVG. Finally, I replaced parts of the SVG with placeholders in place of title, description, type, and picture.\nBelow, you can see an excerpt of the cards' SVG template. Handlebars placeholders are inside curly braces.\n\u0026lt;!-- TITLE --\u0026gt; \u0026lt;rect x=\u0026#34;20\u0026#34; y=\u0026#34;320\u0026#34; width=\u0026#34;284\u0026#34; height=\u0026#34;45\u0026#34;\u0026gt;\u0026lt;/rect\u0026gt; \u0026lt;text id=\u0026#39;title{{ i }}\u0026#39; fill=\u0026#34;{{ fontColor }}\u0026#34; font-family=\u0026#34;MadScience\u0026#34; font-size=\u0026#34;28\u0026#34; font-weight=\u0026#34;normal\u0026#34;\u0026gt; \u0026lt;tspan x=\u0026#34;50.0940004\u0026#34; y=\u0026#34;330\u0026#34;\u0026gt;{{ title }} \u0026lt;/tspan\u0026gt; \u0026lt;/text\u0026gt; \u0026lt;!-- DESCRIPTION --\u0026gt; \u0026lt;rect x=\u0026#34;40\u0026#34; y=\u0026#34;360\u0026#34; width=\u0026#34;250\u0026#34; height=\u0026#34;143\u0026#34;\u0026gt;\u0026lt;/rect\u0026gt; \u0026lt;text id=\u0026#39;description{{ i }}\u0026#39; fill=\u0026#34;{{ fontColor }}\u0026#34; font-family=\u0026#34;DINPro-Regular, DINPro\u0026#34; font-size=\u0026#34;20\u0026#34; font-weight=\u0026#34;normal\u0026#34;\u0026gt; \u0026lt;tspan x=\u0026#34;137.000014\u0026#34; y=\u0026#34;452\u0026#34;\u0026gt;{{{ description }}}\u0026lt;/tspan\u0026gt; \u0026lt;/text\u0026gt; At this point I could batch create all the SVG describing the cards. But it was still text, and I needed pixels ready to print !\nSVG ‚Üí PNG I tried various SVG renderers and encountered various rendering glitches (badly rendered fonts, blurring not supported) with non browser based SVG renderers. I finally settled on using Firefox as a rendering engine and used its screenshot feature to screenshot pages containing SVGs.\nThe screenshot \u0026ldquo;command\u0026rdquo; can be called from the console and the resolution of the screenshot can be controlled through the --dpr flag. Having a high resolution was very important for the finaly quality of the prints.\n:screenshot --fullpage --dpr 2 Dynamically sized text One problem I encountered was that some title and descriptions were longer than others and could not fit in the area I had envisionned for them. It was needed to reduce the font dynamically so that it could fit.\nFortunately, all the hard work of sizing the font, decreasing it until it fits a given rectangle, while taking care of wrapping, had been done in d3plus-text so I had only to include the library and call its methods to have my title and description automatically fitted.\nHaving the ability to execute Javascript to do dynamic font-sizing was also one of the reason behind choosing a browser as the SVG renderer.\nAutomating the rendering of the the cards proved important since it was possible to change the design of the cards late in the process, based on designs made by a graphic designer friend. If this had not been scripted, this would have meant changing all the 269 cards üò±.\n Some of the cards (one of them has yet to have a good picture)\n  The board For the board, I used Sketch (a vector editor). Its scripting abilities and Symbol made my life a little easier.\n ‚ÑπÔ∏è Symbols are ways to reuse graphical elements in Sketch. You can also set Overrides in the reused parts to reuse while replacing some part of the reused content.\n Setting Symbol overrides Each square had a little icon inside. I used Sketch scripting ability and its Override feature to automatically set the right icon for each square based on its index.\nif (i % 2 == 1) { square.overrides.icon = \u0026#39;atom\u0026#39; } else if (i % 2 == 2) { square.overrides.icon = \u0026#39;microscope\u0026#39; } Arranging the squares along a path There were several ideas for the path drawn by the squares. The number of total squares was also not fixed at first. To be able to quickly react to new suggestions and changes, I used the scripting feature of Sketch to automatically arrange the squares along a path.\nTo do that, I\u0026rsquo;d draw a path in Sketch, export it to SVG, load it in Firefox and use the getPointAtLength API to generate positions for the squares. Then I copy/pasted those positions back to sketch, and use a script to layout the squares according to those positions.\nThis allowed me to be able to change the square size, number, and path even at the end of the project. This proved important to be able to incorporate suggestions from other people : using the script features in Sketch made decisions reversible. This was good for rapid iterations.\nConclusion I was really proud to have produced a real physical object. I normally deal with software projects that get maintained and changed for a long time (hence the \u0026ldquo;soft\u0026rdquo; in software). Physical projects are interesting in the sense that you cannot change them once shipped : once printed, you will not be able to go back and change the cards. This is a big constraint but it is also quite liberating since hacks and dirty tricks are much less of a problem.\nMore importantly, I was really glad to have found a method so that anyone interested could participate. It resulted in a lot of good memories in the form of cards. Thanks to Julie, Eleonore, Valenti, Ricardo, Juliette, Sue, Aladin and everybody who has participated in this project.\nSome of the code to generate cards can be found here.\n"});index.add({'id':1,'href':'/posts/','title':"Posts",'content':""});index.add({'id':2,'href':'/posts/whispersync-reverse-engineering/','title':"Reverse engineer whispersync",'content':"I am a big fan of my Kindle. This is the device I\u0026rsquo;d bring over to a desert island. I am also a fairly frequent user of the highlight feature where you can select a bit of text you like and save it. One thing is bothering me though: the lack of open API on the Kindle to retrieve the data about me. Amazon provides the my-clippings.txt file on the Kindle and the \u0026ldquo;Export my annotations via e-mail\u0026rdquo; feature, but both these features cannot be done in the background automatically, and the last read position is not available. I want moar !\nI want to get the raw data:\n to print a little book with all my annotations to retrieve my last read position and see in which periods of my life I tend to read most (reading less would be a good indicator of stressful periods) to put the data in my own personal space : my cozy (I work there). I could for example randomly display favorite quotes in my Cozy-Home, or have a \u0026ldquo;books\u0026rdquo; app with a public page with all my books. That would be the digital equivalent of a bookshelf. The bookshelf as a means of sharing good books that you‚Äôve read is lost with the Kindle. I wish I could easily share with my friends my reading list. goodreads.com would be another way to do that, but I‚Äôd prefer to have the data at my disposal.  The possibilities are endless\u0026hellip; but first, I needed to get access to the data. A long time ago, I tried to access this data via Kindle web but could not pass the login screen via scraping: there was if I recall well, credential encryption on the application side, and I had not managed to redo it correctly.\nRecently, I have seen a presentation on using mitmproxy to discover HTTP APIs used by apps. It gave me motivation to start again on this project: this time, instead of web scraping, I\u0026rsquo;d try to understand how the Kindle communicates with Amazon and try to emulate the same HTTP requests to access my data.\nSetup a man in the middle on a Kindle app Disclaimer: do not attempt man-in-the-middle attacks on devices or accounts that are not your own. To successfully conduct this project, you need to have physical access to the device to install an SSL certificate authority.\nTo see the flow of communication between an Android device and a remote HTTP based APIs, things are a bit more involved than from a web browser: in the web world we have access to the network inspector which helps us record data, replay calls, see requests and responses, etc\u0026hellip; There is no such thing for Android or iOS. The solution is to do a man-in-the-middle attack on our device: proxying and recording all traffic through a controlled access point.\nThe setup is briefly described below:\n A Raspberry Pi runs as a wifi access point (through hostapd) Every packet going through the access point is redirected to mitmproxy (in the transparent mode fashion) HTTPs man-in-the-middle is made possible thanks to a custom CA authority installed on the whispersync client device A real or virtual (for example with Genymotion) Android 5 device Kindle for Android installed on the Android device (the Play store can be installed on Genymotion)   ‚ÑπÔ∏è It is also possible to use iOS but it is easier to have access to a virtual Android device since you do not have to own a Mac\n  ‚ÑπÔ∏è On Android, it is possible to use user certificates until Android 7 Nougat. After Android 7 Nougat, apps will not use user certificates by default. More information here.\n Here is a good article to set everything up.\nAfter all this setup (a bit long and tedious but not hard), it is possible to record HTTP dumps of the traffic between the Kindle app and Amazon.\nssh pi@192.168.50.10 tmux a -t 0 # launch mitmdump and write request/response to outfile mitmdump --mode transparent -w outfile # Use the Kindle app to generate traffic # ctrl-c to stop the proxy exit # At this point, outfile contains all the requests and responses in the mitmproxy format.\nRecording HTTP dumps mitmproxy uses a custom format to store dumps. It is not very interoperable: querying and extracting data from the dumps is a bit difficult. HAR is a standard format used for example in Chrome and Firefox (Network inspector tabs in both browser can import/export the HAR format). The HAR format underlying format is JSON which makes it readable and interoperable with tools like jq that are really handy for filtering / querying.\nThe mitmproxy repository contains a script to transform a mitmproxy dumpfile into a HAR file.\nTo convert a mitmproxy dump into an HAR file:\ngit clone https://github.com/mitmproxy/mitmproxy.git mitmproxy # to have access to the HAR conversion script pip install mitmproxy # to have the mitmdump command # Extract the dump from the Raspberry Pi rsync -aPrs pi@192.168.50.10:outfile dump.mitmproxy # Convert mitmproxy format to HAR format (JSON based format) mitmdump -vvv -n -r infile.dump -s mitmproxy/examples/complex/har_dump.py --set hardump=./outfile.har Understanding the flow With jq, we can extract requests URLs, which is handy to start understanding the flow of communication between Amazon and our device.\n$ cat dumps/dump.har | jq -rc \u0026#39;.log.entries | map(.request.url)\u0026#39; \u0026#34;https://54.239.22.185/FirsProxy/registerDevice\u0026#34;, \u0026#34;https://54.239.22.185/FirsProxy/registerDevice\u0026#34;, \u0026#34;https://54.239.22.185/FirsProxy/registerDevice\u0026#34;, \u0026#34;https://54.239.22.185/FirsProxy/registerDevice\u0026#34;, \u0026#34;https://54.239.22.185/FirsProxy/getStoreCredentials\u0026#34;, \u0026#34;https://52.46.133.19/FionaTodoListProxy/syncMetaData\u0026#34;, # Unique URLS cat dumps/dump5.har | jq \u0026#39;.log.entries | map(.request.url) | sort | unique\u0026#39; # Filter all requests with a particular URL cat dumps/dump5.har | jq \u0026#39;.log.entries | map(select(.request.url == \u0026#34;\u0026lt;MY_URL\u0026gt;\u0026#34;))\u0026#39; Registration and request signing The first call the device makes when logging in is a registerDevice call. It contains both login and password and is used to register a device on Amazon. After replaying this request through curl, I had a \u0026ldquo;Wrong password\u0026rdquo; response. It is because Amazon sends a two factor authentication email and you have to replay (again) the registerDevice call with the value from the two factor authentication email in the password field to get through.\nAt this point a new device is visible on Amazon Kindle site üôå. The next things to do is to fetch the list of books.\nThe problem now is that we can see that every subsequent request to Amazon has a X-ADP-Request-Digest: every request is \u0026ldquo;signed\u0026rdquo; with the help of a certificate received in the registerDevice call.\nBelow, you can see an example request on the syncMetadata route used to get the list of books:\n{ \u0026#34;startedDateTime\u0026#34;: \u0026#34;2020-05-10T14:21:42.217752+00:00\u0026#34;, \u0026#34;time\u0026#34;: 6532, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://52.46.133.19/FionaTodoListProxy/syncMetaData\u0026#34;, \u0026#34;httpVersion\u0026#34;: \u0026#34;HTTP/1.1\u0026#34;, \u0026#34;headers\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;X-ADP-Request-Digest\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;SIG1tis85OWFqJqbzy0Z0xBzBCI3/88e9p/2jr8UvTAUQCuil5ED0833peNeKPp1dIMdVAs/INcUR//xvCJu+ngyP9olVSda/IBBxM2fftVGIDEVuQqMSC9P+O/pZMhaAJpvxIm78M52OB+lNIYXjE0Kr1OB0mmOo4iVu45aRio8hZDlmDG07zjVHnlQHE5sUjzOMnYBFC6VXw+srjYfo6dTptwSKNX11A0naG+tjcuxnglAE3R9U8/+pVr/uFNT4ou+0cQs2KbV0/4tYEIbOogC1JgjNNt4hyb2l91QED7Aj+A/DFcKBT+XNkjAUAAI1//HhCtxqCNtbu1E1sRReQ==:2020-04-10T14:21:40Z\u0026#34; } ] } } Signing the request means that I needed to use the right key to sign (I was pretty confident that the privateKey receive in the registerDevice call was the one to use) sign the right data = find the fields from the request (and in which order) that were used to make a fingerprint of the request\nFortunately, after a bit of searching I came across the repositories of lolsborn (readsync and fiona-client) that had implementation of request signing for the whispersync API.\ndata = \u0026#34;%s\\n%s\\n%s\\n%s\\n%s\u0026#34; % \\ (method, url, time, postdata, self.adp_token) rsa = RSA.load_key_string(str(self.private_pem)) crypt = rsa.private_encrypt(hashlib.sha256(data).digest(), RSA.pkcs1_padding) sig = base64.b64encode(crypt) From readsync source code.\nFrom this bit of code, I could see which fields were used and in which order. I now needed ‚Äúonly‚Äù to convert it to Javascript.\nWith the help of node-forge and node-rsa, after a fair bit of struggle, I managed to have the right signature. I found it difficult even with two example implementations to get the signature exactly right (I am not an expert in crypto technologies and did not know both libraries, so I spent a little bit of time trying to jam the certificate and values in every possible ways üôÉ).\nHaving a bad signature is not immediately obvious since you have to send a request to Amazon to check it (and if it‚Äôs bad, Amazon sends an Internal Server Error). Using a recorded dump to have an example of the right signature and using it in a Jest test with a fixed date (since the date is used in the request) was very helpful as the feedback loop was very quick.\n ‚ö†Ô∏è I had to use two different libraries to get the same signature. I am sure it is possible to use only node-forge though. ‚ÑπÔ∏è The private key is a PKCS8 certificate in DER format encoded in base64. ‚ùìI wonder why to sign the requests, the devices do not generate a private/public key pair and transmit the public key to Amazon: it is a bit unusual to have something private fly on the network.\n Sidecars After cracking the signing part, it was possible to call the syncMedata route, with a proper digest header, to get all the books in our library (yay!).\nBut, the challenge was not done yet: I was most interested in getting the metadata on the book: my highlights, annotations and last page read. I needed to find the call that was retrieving all this data.\nWhen searching for the content of a highlight in the dump, I could not find anything ü§î. When filtering the URLs of the dump with the identifier of the book (the ASIN in Amazon parlance), some URLs looked interesting:\nhttps://72.21.194.248/FionaCDEServiceEngine/FSDownloadContent?type=EBOK\u0026amp;key=\u0026lt;MYASIN\u0026gt; https://54.239.26.233/FionaCDEServiceEngine/sidecar?type=EBOK\u0026amp;key=\u0026lt;MYASIN\u0026gt; FSDownloadContent was the call to get the content of the book. But what was the sidecar URL ? Sidecars sounds like something loaded to the side of the book, maybe containing annotations ?\nThe body of the response was base64 encoded, and after a base64 --decode, bingo! I could read the content of my book highlights into my terminal.\n Now, this is a proper sidecar\n  # Using the ad-hoc CLI tool to fetch a sidecar in binary format and decode it $ yarn -s cli fetch sidecar --no-parse B01056E716 | base64 --decode CR!3WET39TJ553PXCAHWBHXQ1RT_PAR^Ãµ]^Ãµ]BPARMOBI\u0026amp;\u0026amp;\u0026lt;@6^^ !b#f$%*f\u0026quot;V F BPAR8FYDATApce plaisir puis dans l agressivit ainsi que cet amour de la servilit grgaire n DATAC tait la mme illusion, procdant de la mme volont de s illusionner soi-mme.8 DATAon n avait pas encore invent le systme actuel qui consiste assommer les gens coups de matraque et les exterminerDATAaffreuse tension. Le dimanche matin, la radio annonait la nouvelle que l Angleterre avait dclar la guerre l Allemagne. ƒà DATAils n aspiraient rien d autre qu enchaner, dans un effort silencieux et pourtant passionn, des strophes parfaites dont chaque vers tait pntr de musique, brillant de couleurs, clatant d images.P DATAnous qui attendons de chaque jour qui se lve des infamies pires encore que celles de la veille, nous sommes nettement plus sceptiques quant la possibilit d une ducation morale des hommes. BKMK4W*WW*ﬁ≠$#BKMK4^,^^,ﬁ≠BKMK4~y:~yﬁ≠BKMK4ﬁ≠! BKMK4`ﬁ≠BKMK1ﬁ≠BKMK4 (I\u0026rsquo;ve added line breaks for clarity)\nAs you can see, the problem was that the decoded content was a bit garbled : accents are missing and annotations are not delimited correctly. Turns out, Amazon uses a custom binary format for its sidecars. After encryption, binary decoding, what an adventure ü§†!\nWhen searching for the sidecar application type, I stumbled upon KSP (Kindle Server Proxy), a project to connect a Calibre library to the Kindle seamlessly. It works as a middleware between Amazon and your Kindle, implementing routes of the Whispersync API. It serves content from your Calibre database, or from Amazon as needed: if a book is from Amazon, content is served from Amazon, otherwise it‚Äôs served from a local database.\nKSP did not need to read sidebars as it was sufficient for it to only pass the content without reading it. It did however need to know how to write sidebars. The code was informative on the binary format used, but I knew I needed to code a sidebar parser.\nBytes in color At this point, I decided to have a look at the bytes in a graphic form to understand better what was going on. I had read recently about visualising a binary in color so I figured I could try to do the same thing. By reimplementing, I would have more control onto the visualisation and hopefully it would serve when debugging the parser.\nI fired up codesandbox and wrote an app that when given a base64 string would output its bytes colored based on the value of their value. I used the HSL color space with the value of the byte controlling the hue so that nearby valued bytes have similar colors. It is very similar to cortesi\u0026rsquo;s binvis but this one I could hack more easily to serve my needs.\n Coloring bytes..\n  Seeing the data colored helps to see the different parts of the binary format and find patterns. For example, here we can see at the bottom a red/green check pattern. It is a two byte pattern, and we know that at this part, we should have text so it is a good clue that the text is encoded in UTF16.\nThis app was really helpful when writing the parser since I could better understand on which part the parser was struggling.\nTo write the parser, I used binary-parser. Its API make it easy to make a parser. To be able to conjugate it with the binary viewer, I monkey patched the code to add before/after indexes to each field so that I could see each field separately in the viewer.\nHere is an extract from the parser:\n const sidecarParser = new Parser() .endianess(\u0026#39;big\u0026#39;) .string(\u0026#39;guid\u0026#39;, { length: 32, stripNull: true }) .seek(4) .buffer(\u0026#39;v1\u0026#39;, { length: 4 }) .buffer(\u0026#39;v2\u0026#39;, { length: 4 }) .buffer(\u0026#39;v3\u0026#39;, { length: 4 }) ... .uint16(\u0026#39;next_id\u0026#39;) .seek(4) .uint16(\u0026#39;index_count\u0026#39;) .seek(2) .uint16(\u0026#39;bpar_ptr\u0026#39;) .saveOffset(\u0026#39;bpar_ptr_index_\u0026#39;) and its usage:\nconst rawData = new Buffer() // binary data const data = sidecarParser.parse(data) // \u0026gt; { index_count: 16, next_id: 5, bpart_ptr: 300, guid: ‚ÄòCPAR‚Ä¶.‚Äô } The structure of the binary is as follows:\n A header Pointers to the annotations Annotations data  When parsed, it looks like:\n Incredible endia To format the bytes extracted from the data section, I used the Uint{8/16}Array APIs from the browser that serves as views on a byte buffer. This worked well for Uint8/16 integer buffers. The problem I faced was with the string buffers : the Uint{8/16}Array APIs work in the platform endianness (to use the native APIs where possible). My computer was in little endian whereas the annotations were encoded in utf16 big endian. This meant that if I wanted to read a buffer with String.fromCharCode I had either to swap the endianness of the buffer or to use a DataView (Javascript API to read / write data independent of the endianness of the platform). I did not know DataView at this point so I swapped the bytes but DataView would have worked since you can choose the endianness when reading a value.\nData corruption To test the parser, I downloaded sidecars through the whispersync client I was building and dumped their contents in the test folder. When trying to parse them, the parser was struggling and I could see many \u0026ldquo;EF BF BD\u0026rdquo; bytes colored in blue.\n Corrupted bytes visible in blue\n  Those bytes were mainly present in the section of the binary containing pointers to the annotations locations. This made the parser fail. After a bit of struggling trying to shift the data or ignore those bytes, I searched for \u0026ldquo;EF BD BD\u0026rdquo;.\n EF BF BD is UTF-8 for FFFD, which is the the Unicode replacement character (used for data corruption, when characters cannot be converted to a certain code page). https://stackoverflow.com/questions/47484039/java-charset-decode-issue-in-converting-string-to-hex-code\u0026gt;\n I figured out that the request JS library used to fetch HTTP responses tried to decode the data as UTF-8 by default and failed (as sidecars are transmitted as binary data over the network). Solution was to put { encoding: null } as the request options so that it returns a Buffer. The buffer can then be encoded in base64 to print it to the console with no garbled character. This base64 output can piped into base64 --decode before dumping it to disk (console.logging the buffer would try to decode the data as utf-8).\nHTTP server to explore content At some point, to be able to explore annotations, it seemed to me that the CLI was a bit limited to explore the content easily. I added a HTTP server serving an index of the books and a book page showing the annotations. The content is fetched from Amazon if it is not on disk, and it is then saved in JSON format for later access.\nI used fastify which is an alternative to express that promises to be much faster. It worked well for my simple purposes.\nHere are two screenshots:\n    Conclusion All in all, it was a really good experience, I learned about\n Man-in-the-middle in practice Encryption Binary decoding String encodings  There was a lot of hurdles but I was really pumped up by the fact that the data recovered was important to me : I like reading and am now happy that my highlights will live in a format that I will be able to read in a long time for now. I am also happy to have them in a simple JSON text format that I can query using tools I am familiar with jq, rg or grep.\nNext plans:\n  make a Cozy connector using the whispersync-client to have my annotations automatically synced to my Cozy üöÄ.\n  see if it would make sense to have some kind of integration with Calibre\n  The code is available here for education purposes: whispersync-lib-code.\nResources Several resources were of great help when building this project.\n  Lolsborn\u0026rsquo;s repos : readsync and fiona-client\n Useful for request signing and starting out the Javascript structure of the Javascript client (turns out Scala is quite quick to convert to Javascript).    KSP (Kindle Server Proxy)\n Implementation of a middleware server for Kindle, seamlessly connecting Calibre and Kindle Recreates the sidecar, useful to understand the format of the sidecar    Reverse engineering a file format on WikiBooks.\n  Good general information on how to start with the decoding of a binary format.\n "});})();